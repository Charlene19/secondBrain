+++
title = "ScrapperPy"
author = ["Charlène"]
date = 2021-03-01
tags = ["Python"]
draft = false
+++

:python:

[QustionsObjectif](20210309134055-qustionsobjectif.org)

Création d'un scrapper pour les offres d'emploi de programmeur informatique Java.
Avec plusieurs mots clef : développeur, java, paris, seine-saint-denis, débutant.

Je vais utiliser le scrapper Scrappy, qui va me renvoyer mes données en JSON.
Je vais après faire une utilisation de mes données.

Je m'appuies sur le livre de Ryan Mitchell : Web Scraping with Python Collecting more data
from the modern web.

:beautifulSoup:

Il y existe différents parser : html.parser, lxml, html5lib.

:bsException:

Il faut prévoir une erreur dans la recherche d'url.

from urllib.request import urlopen
from urllib.error import HTTPError

avec un try catch qui offre une méthode en cas de levée d'erreur.

Les méthodes de Bs :

_find and find\_all_ : tag, attributes, recursive, text, limit, keywords.

> The attributes argument takes a Python dictionary of attributes and matches tags
> that contain any one of those attributes. For example, the following function would
> return both the green and red span tags in the HTML document:
> .find\_all('span', {'class':{'green', 'red'}})

_recursive_ : La recherche si est true va rechercher dans les
attributs enfants. Si faux, juste au top niveau.

_text_ : va s'intéresser au texte recherché.

```text
nameList = bs.find_all(text='the prince')
print(len(nameList))
```

**Attention** : certains mot-clefs sont protégés en Python comme
 'class', il faut alors mettre un underscore : 'class\_' pour pouvoir
 faire appel à ce tag.

:BsObject:

Il existe 4 objets BeautifulSoup :

> BeautifulSoup objects
> Instances seen in previous code examples as the variable bs
> Tag objects
> Retrieved in lists, or retrieved individually by calling find and find\_all on a
> BeautifulSoup object, or drilling down, as follows:
> bs.div.h1
> However, there are two more objects in the library that, although less commonly
> used, are still important to know about:
> NavigableString objects
> Used to represent text within tags, rather than the tags themselves (some func‐
> tions operate on and produce NavigableStrings , rather than tag objects).
> Comment object
> Used to find HTML comments in comment tags, <!--like this one--> .

_next\_siblings_ permet d'extraire les données sur les colonnes côte à
orcôte sans le titre.

POur optimiser la recherche, le mieux est de stocker les résultats dans un set. Un set
ne permet pas la duplication d'élements.

> Python has a default recursion limit (the number of times a pro‐
> gram can recursively call itself) of 1,000. Because Wikipedia’s net‐
> work of links is extremely large, this program will eventually hit
> that recursion limit and stop, unless you put in a recursion counter
> or something to prevent that from happening.

La librairie [Requests](https://requests.readthedocs.io/en/master/) est une autre librairie pour obtenir les GET comme urlopen.
